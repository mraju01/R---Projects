title="M3 Project - ALY 6010"


<P>

<BR>

<CENTER>

<FONT size=6, color="blue">
Maheswar Raju </FONT>

<FONT size=4, color="green">
Northeastern University </FONT>


<P>

<FONT size=5.5, color="#008080"> ALY 6010 - 71579 </FONT>


<P>

<BR>
<FONT size=5, color="Grey"> 
<BR>
**Maheswar Raju Narasaiah**

<FONT size=5, color="Black"> 
Prof: Dr. Dee Chiluiza 

Date:  `r format(Sys.time(), '%d %B, %Y')`

</CENTER>

<P>
<BR> <B>
  <FONT SIZE = 5, COLOR ="#f70d1a">
  1. INTRODUCTION 
  </FONT>
</BR></B>
   
   <FONT SIZE = 4.75, COLOR ="#f94c56">
   **A. Confidence Interval, it's Importance and Application**
   </FONT>
   <P>
<FONT SIZE = 4.5>


-- ***Definition***

A confidence interval (CI) is a set of numbers that includes the value of a previously unknown population parameter. These intervals provide a plausible domain for the parameter based on the qualities of the sample data. Confidence intervals are formed from sample statistics and produced using a predetermined confidence level(Poole, 1987).

Because it is often hard to measure entire populations, population parameters are highly variable. A sample can be used to estimate these parameters. Due to random sampling error, however, the estimates rarely exactly equal the parameter.

The confidence level is the long-run probability that a set of confidence intervals will encompass the real value of a population parameter.

-- ***Importance of Confidence Interval***

The majority of what we do in statistics includes using a sample to answer a research question. A confidence interval expresses the degree of uncertainty or mistake associated with an estimated statistic. It should be noted that the interval can only reflect the uncertainty introduced by taking a sample from the underlying population (that is, sampling variability). A confidence interval cannot infer non-sampling concerns such as bias, measure accuracy, or generalization of the result (Hazra, 2017).

Generally, the confidence interval takes the form:

<P>
  *C.I. = statistic ± multiplier × standard error of the statistic*

</P>

The "statistic" in this calculation is the estimate from our sample; it is our best guess at the true value in the population. This statistic could be a mean, a percentage, a difference in means, a regression coefficient, a relative risk, a hazard ratio, or something else. The "multiplier" is a value from a specific theoretical distribution (for example, the normal distribution or the t distribution); the suitable distribution is determined by the type of statistic. The value chosen from that distribution expresses the "confidence" that the unknown parameter will fall inside the confidence interval. The variability due to sampling is represented by the "standard error of the statistic."

Different random samples collected from the same population will almost certainly provide somewhat different intervals. If you take a large number of random samples and compute a confidence interval for each one, a percentage of them will contain the parameter (Bluman, 2014).


Fortunately, inferential statistics methods may analyze a sample while compensating for the uncertainty 
that comes with collecting samples. Confidence intervals encompass the point estimate with a margin 
of uncertainty to assist us in comprehending how wrong the estimate could be.

-- ***Applications of Confidence Interval in News Industry***

When poll results are revealed, confidence intervals are frequently shown on the news. This is an example from the October 2018 issue of the CNN Press:

According to the most recent CNN Post survey, 56 percent of respondents supported Trump, while 39 percent supported Biden. The CNN News Post telephone poll of 2,028 individuals was conducted between March 6 and 16, with a margin of error of 3.5 percentage points. (Emphasis added.)

Even though it is not indicated, the margin of error presented here was most likely the 95 percent confidence interval. Simply put, there is a 95 percent chance that between 35.5 percent and 42.5 percent of voters will vote for Biden (39 percent plus or minus 3.5 percent). In contrast, there is a 5% possibility that less than 35.5 percent of voters or more than 42.5 percent of voters will support Biden.

The accurate statistical definition of the 95 % confidence interval is that if the telephone poll were undertaken 100 times, 95 percent of respondents in favor of Biden would fall within the calculated confidence intervals, while 5% of respondents in favor of Biden would fall beyond the confidence interval range.


</FONT>

<FONT SIZE = 4.75, COLOR ="#f94c56">
   **B. Hypothesis Testing, it's Importance and Application**
   </FONT>
   <P>
<FONT SIZE = 4.5>

-- ***Definition***

Hypothesis testing determines whether a specific assumption holds true for the entire population. It is a statistical instrument. It evaluates sample data from the entire population to determine the validity of conclusion.

The hypothesis idea is based on the likelihood of an event occurring. It determines whether or not the primary hypothesis results are correct. It is commonly used in biological research, criminal trials, marketing, and manufacturing.

-- ***Importance of Hypothesis Testing***

The most important advantage of hypothesis testing is that it allows you to assess the strength of your claim or assumption before including it into your data collection. Furthermore, hypothesis testing is the sole valid approach for determining if something "is or is not." Other advantages include:

- Hypothesis testing creates a framework for drawing data inferences for your population selected.
- It helps the researcher extrapolate data from a sample to a larger population.
- The analyst can use hypothesis testing to see if the sample data is statistically significant.
- Hypothesis testing is one of the most important stages in any systematic examination for determining the reliability and trustworthiness of results.
- It is advantageous to establish links between the underlying theory and specific research concerns.

-- ***Applications of Hypothesis Testing In Advertising Campaign***

Suppose, A organization has hired an external data analytics team to check if their new marketing program is contributing to increasing in sales or not. To check this, the data analytics team is comparing the sales of the previous year, when the marketing program was not put in place, and sales in the first quarter after new marketing strategies were implemented. Here, they have collected sales data from the first quarter as the year is still ongoing and the first quarter has just ended.

If μp denotes the average sales of previous year and μs denotes the average sales of first quarter in current year, then we are essentially testing the claim that μp=μs.

Hence the appropriate hypothesis test to conduct is the right-tailed test with the following hypotheses:

              H0 :: μp=μs

              H1 :: μp<μs

Here, the null hypothesis represents both having the same sales (indicating our marketing program is not working) and the alternative hypothesis represents the groups having an increase in sales (indicating our marketing program is effective).


</FONT>


<P>
<BR> <B>
  <FONT SIZE = 5, COLOR ="#f70d1a">
  2. ANALYSIS 
  </FONT>
</BR></B>

<P>

<FONT SIZE = 4.5>
In this below section, we will perform various statistical analysis on our Data to make inferences and address our problems.
<FONT/>

```{r message=FALSE, warning=FALSE}

# Library Used for M3 Project
#####################################
library(magrittr) ## Fetching magnittr
library(knitr)
library(plyr)
library(dplyr)
library(readxl)
library(gridExtra)
# library(CGPfunctions)
library(RColorBrewer)
library(lattice)
library(ggplot2)
library(DT)
library(kableExtra)




# Datasets used in Project##################
###########################################
## Sample data
SData <- read_excel("~/Desktop/Intro To Analytics - ALY 6000/ALY 6000 - Project/Data Sets/M3ProjectData.xlsx")

## Removing NA Values from each column using na.omit() function
S1 <- na.omit(SData$`Sample 1`)
S2 <- na.omit(SData$`Sample 2`)
S3 <- na.omit(SData$`Sample 3`)
S4 <- na.omit(SData$`Sample 4`)
S5 <- na.omit(SData$`Sample 5`)
S6 <- na.omit(SData$`Sample 6`)
```

***About the Data Set***
<P>
The data contains population and sample taken from population and placed into different columns of spreadsheet.


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.1. Presenting First 15 Observations of Data Set
</FONT>
</BR></B>

<FONT SIZE = 4.5>
In this section, we will perform the head function to first 15 observation from our data
</FONT>

```{r message=FALSE, warning=FALSE}

# Creating a new objects for fetching first 15  records####
###########################################################
hSData <- head(SData, 15)



# Present the table using kableExtra Package###############
##########################################################
hSData %>%
  kbl(
    caption = "Table 1 : First 15 Observation of Data Set",
    format = "html"
  ) %>%
  kable_material_dark(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***


- After looking at first 15 rows, we clearly can say that the data type of all our variables are continuous variable, so we can quantitative data in front of us for our analysis.
- After doing the some basic analysis on excel, the frequency of data is mostly concentrated between 0.63 to 2.00, with some outliers

</FONT>

<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.2. Basic Descriptive Statistics : Population and Sample 1
</FONT>
</BR></B>

In this section, we will get basic desciptive statistics of population and sample 1 and present in well-organized table.


```{r message=FALSE, warning=FALSE}


# Population : Basic Descriptive Statistics##################
######################################################
MeanPop <- mean(SData$Population)
MedianPop <- median(SData$Population)
StdPop <- sd(SData$Population)


## Vector Creation for Population
####################################
vectorPop <- c(MeanPop, MedianPop, StdPop)


# Sample 1 : Basic Descriptive Statistics###
####################################
MeanS1 <- mean(S1)
MedianS1 <- median(S1)
StdS1 <- sd(S1)


## Vector Creation for Sample 1####
####################################
vectorS1 <- c(MeanS1, MedianS1, StdS1)


# Matrix Creation for basic descriptive statistics#####
######################################################
SData_Table <- matrix(c(vectorPop, vectorS1),
  nrow = 2,
  byrow = TRUE
)


# Rounding Digits in Matrix##################
######################################################
SData_Table_Rounded <- round(SData_Table, digits = 2)

## Naming Columns and Row Names in Table#######
colnames(SData_Table_Rounded) <- c("Mean", "Median", "StDev") # nolint

rownames(SData_Table_Rounded) <- c("Population", "Sample 1")


# Table Creation of of Matrix Using Knitr Package##################
######################################################
SData_Table_Rounded %>%
  knitr::kable(
    caption = "Table 2 : Descriptive Statistics of Populations and Sample 1",
    format = "html"
  ) %>%
  kable_material_dark(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***

- After looking at table, we can say that there is difference between population and sample 1.
- We can see that mean of sample 1 is 1.03, which is lower than population Mean, but we can't conclude because we have to perform some more analysis to check if difference is significant.


</FONT>

<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.3. Sample 1 : Confidence Interval for Sample Mean
</FONT>
</BR></B>

In this section, first we are going to find out the confidence interval of mean of Sample with 90%, 96% and 99% Confidence using Z-test, and find out if 
population mean value lies within the calculated confidence intervals


```{r message=FALSE, warning=FALSE}


# Sample 1 : Basic Descriptive Statistics##################
######################################################
MeanS1 <- mean(S1)
StdS1 <- sd(S1)
nS1 <- 160


# Creating Object for 90% Confidence Interval##################
##########################################################
CL90S1 <- 0.90


alp90S1 <- (1 - CL90S1) # Calculating Alpha Value####


Z90LS1 <- qnorm(alp90S1 / 2) # Calculating Z value for Margin of Error###
Z90RS1 <- qnorm((alp90S1 / 2) + CL90S1) # Calculating Z value for Margin of Error### # nolint

# Calculating Margin of Error
##################
MarErr90S1 <- Z90RS1 * (StdS1 / sqrt(nS1))

t
##################
CLL90S1 <- MeanS1 - MarErr90S1 # Creating Objects for Confidence Interval: Upper and Lower Limi
CLU90S1 <- MeanS1 + MarErr90S1 # Creating Objects for Confidence Interval: Upper and Lower Limi


##################
wd90S1 <- CLU90S1 - CLL90S1 # Calculation of C.I. Width for 90


##################
vectorCI90S1 <- c(Z90LS1, Z90RS1, MarErr90S1, CLU90S1, CLL90S1, wd90S1) # Vector Creation for 90% C.I.


# Creating Object for 96% Confidence Interval################
########################################
CL96S1 <- 0.96


alp96S1 <- (1 - CL96S1) # Calculating Alpha Value


Z96LS1 <- qnorm(alp96S1 / 2) # Calculating Z value for Margin of Error
Z96RS1 <- qnorm((alp96S1 / 2) + CL96S1) # Calculating Z value for Margin of Error

# Calculating Margin of Error
MarErr96S1 <- Z96RS1 * (StdS1 / sqrt(nS1))

# Creating Objects for Confidence Interval: Upper and Lower Limit
CLL96S1 <- MeanS1 - MarErr96S1
CLU96S1 <- MeanS1 + MarErr96S1

# Calculation of C.I. Width for 96
wd96S1 <- CLU96S1 - CLL96S1

# Vector Creation for 96% C.I.
vectorCI96S1 <- c(Z96LS1, Z96RS1, MarErr96S1, CLU96S1, CLL96S1, wd96S1)




# Creating Object for 99% Confidence Interval
########################################
CL99S1 <- 0.99

# Calculating Alpha Value
##################
alp99S1 <- (1 - CL99S1)

# Calculating Z value for Margin of Error
Z99LS1 <- qnorm(alp99S1 / 2)
Z99RS1 <- qnorm((alp99S1 / 2) + CL99S1)

# Calculating Margin of Error
MarErr99S1 <- Z99RS1 * (StdS1 / sqrt(nS1))

# Creating Objects for Confidence Interval: Upper and Lower Limit
CLL99S1 <- MeanS1 - MarErr99S1
CLU99S1 <- MeanS1 + MarErr99S1

# Calculation of C.I. Width for 99
wd99S1 <- CLU99S1 - CLL99S1

# Vector Creation for 99% C.I.
vectorCI99S1 <- c(Z99LS1, Z99RS1, MarErr99S1, CLU99S1, CLL99S1, wd99S1)



# Matrix Creation for compiling all the Confidence Interval Vectors
S1_Table <- matrix(c(vectorCI90S1, vectorCI96S1, vectorCI99S1), nrow = 3, byrow = TRUE)


## Rounding Digits in Matrix
S1_Table_Rounded <- round(S1_Table, digits = 2)


## Naming Columns and Row Names in Table
colnames(S1_Table_Rounded) <- c(
  "Z Left Value", "Z Right Value",
  "Marg of Error", "Upper C.L.", "Lower C.L.", "Width of C.I."
)

rownames(S1_Table_Rounded) <- c(
  "CI 90%", "CI 96%", "CI 99%"
)

# Table Creation of of Matrix Using Knitr Package
S1_Table_Rounded %>%
  knitr::kable(
    caption = "Table 3: Results  of Sample 1 with
               Different Confidence Intervals",
    format = "html"
  ) %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>
- After performing Z-test, We clearly see that population mean presented in Table 2 is within the 90% , 96%, and 99% confidence intervals for sample 1 mean.
  
- As, we can see as the alpha value is decreasing, our margin of error is increasing, so we can conclude that they are inversely proportional to each other.
  
- Also, when the confidence level increases, the width of between the upper and lower confidence increase, so a trade off occurs.

</FONT>

<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.4. Sample 1 : Sample Size Based On Confidence Interval
</FONT>
</BR></B>
In this secion, we are going to find out sample size based on confidence interval with know standard deviation of popluation and sample 1.

```{r message=FALSE, warning=FALSE}

# Calculate the sample size based on known Std of Sample 1

SizeS190 <- ((Z90RS1^2) * (StdS1^2)) / (MarErr90S1^2)
SizeS196 <- ((Z96RS1^2) * (StdS1^2)) / (MarErr96S1^2)
SizeS199 <- ((Z99RS1^2) * (StdS1^2)) / (MarErr99S1^2)

# Vector Creation for size of Sample 1
SizeS1Data <- c(SizeS190, SizeS196, SizeS199)

# Calculate the sample size based on known Std of Population
SizeP90 <- ((Z90RS1^2) * (StdPop^2)) / (MarErr90S1^2)
SizeP96 <- ((Z96RS1^2) * (StdPop^2)) / (MarErr96S1^2)
SizeP99 <- ((Z99RS1^2) * (StdPop^2)) / (MarErr99S1^2)

# Vector Creation
SizePData <- c(SizeP90, SizeP96, SizeP99)



# Matrix Creation
samplesizematrix <- matrix(
  data = c(SizeS1Data, SizePData),
  nrow = 2,
  byrow = TRUE
)


## Rounding Digits in Matrix
samplesizematrix_Rounded <- round(samplesizematrix, digits = 2)

## Naming Columns and Row Names in Matrix
colnames(samplesizematrix_Rounded) <- c("CI 90% ", "CI 96%", "CI 99%")
rownames(samplesizematrix_Rounded) <- c("Sample 1", "Population")


# Table Creation of of Matrix Using Knitr Package
samplesizematrix_Rounded %>%
  knitr::kable(
    caption = "Table 4: Sample Size based on Known Std of Sample 1
  and Population",
    format = "html"
  ) %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>

- To determine the how many observation, meaning how much sample size is required to make most accurate estimate about the population parameter, depends on three factors: the critical value, margin of error and standard deviation of population when it is known.

- As, we can clearly see from the table that sample size of all the confidence interval are same because it is the formula for sample size is dervied from the margin of error formula, which we have used and presented our results in Table 3.

- Suppose, when standard deviation of population is not known, then we have to to use standard deviation of sample in place of popluation deviation.

</FONT>

<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.5. Sample 2 : Confidence Interval for Sample Mean
</FONT>
</BR></B>

In this section, first we are going to find out the confidence interval of mean of Sample 2 with 90%, 96% and 99% Confidence using t-test, and find out if 
population mean value lies within the calculated confidence intervals, and present in tabular form.



```{r message=FALSE, warning=FALSE}


MeanS2 <- mean(S2)
sdS2 <- sd(S2)
nS2 <- 23

# Degree of Freedom
dfS2 <- nS2 - 1


# Calculating Confidence for 90 %
CL90S2 <- 0.90

# Calculating p Value
p90S2 <- (1 + CL90S2) / 2

# Calculating t value for Margin of Error using qt()
T90RS2 <- qt(p90S2, dfS2)
T90LS2 <- qt(p90S2 - CL90S2, dfS2)


# Calculating Margin of Error
MarErr90S2 <- T90RS2 * (sdS2 / sqrt(nS2))

# Creating Objects for Confidence Interval: Upper and Lower Limit
CLL90S2 <- MeanS2 - MarErr90S2
CLU90S2 <- MeanS2 + MarErr90S2

# Calculation of C.I. Width for 90%
wd90S2 <- CLU90S2 - CLL90S2

# Vector Creation for 90% C.I.
vectorCI90S2 <- c(T90LS2, T90RS2, MarErr90S2, CLU90S2, CLL90S2, wd90S2)



# Calculating Confidence for 96 %
CL96S2 <- 0.96

# Calculating p Value
p96S2 <- (1 + CL96S2) / 2

# Calculating t value for Margin of Error using qt()
T96RS2 <- qt(p96S2, dfS2)
T96LS2 <- qt(p96S2 - CL96S2, dfS2)


# Calculating Margin of Error
MarErr96S2 <- T96RS2 * (sdS2 / sqrt(nS2))

# Creating Objects for Confidence Interval: Upper and Lower Limit
CLL96S2 <- MeanS2 - MarErr96S2
CLU96S2 <- MeanS2 + MarErr96S2

# Calculation of C.I. Width for 96%
wd96S2 <- CLU96S2 - CLL96S2

# Vector Creation for 96% C.I.
vectorCI96S2 <- c(T96LS2, T96RS2, MarErr96S2, CLU96S2, CLL96S2, wd96S2)


# Calculating Confidence for 99 %
CL99S2 <- 0.99

# Calculating p Value
p99S2 <- (1 + CL99S2) / 2

# Calculating t value for Margin of Error using qt()
T99RS2 <- qt(p99S2, dfS2)
T99LS2 <- qt(p99S2 - CL99S2, dfS2)


# Calculating Margin of Error
MarErr99S2 <- T99RS2 * (sdS2 / sqrt(nS2))

# Creating Objects for Confidence Interval: Upper and Lower Limit
CLL99S2 <- MeanS2 - MarErr99S2
CLU99S2 <- MeanS2 + MarErr99S2

# Calculation of C.I. Width for 99%
wd99S2 <- CLU99S2 - CLL99S2

# Vector Creation for 99% C.I.
vectorCI99S2 <- c(T99LS2, T99RS2, MarErr99S2, CLU99S2, CLL99S2, wd99S2)


# Matrix Creation for compiling all the Confidence Interval Vectors
#########################
S2_Table <- matrix(c(vectorCI90S2, vectorCI96S2, vectorCI99S2),
  nrow = 3,
  byrow = TRUE
)


## Rounding Digits in Matrix
S2_Table_Rounded <- round(S2_Table, digits = 2)


## Naming Columns and Row Names in Table
colnames(S2_Table_Rounded) <- c(
  "T Left Value", "T Right Value",
  "Marg of Error", "Upper C.L.", "Lower C.L.", "Width of C.I."
)

rownames(S2_Table_Rounded) <- c("CI 90%", "CI 96%", "CI 99%")

# Table Creation of of Matrix Using Knitr Package
S2_Table_Rounded %>%
  knitr::kable(caption = "Table 5: Results of Sample 2 with
  Different Confidence Intervals", format = "html") %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>


- After performing t-test as sample size was less than 30, We clearly see that population mean also lies within the 90% , 96%, and 99% confidence intervals presented in Table 5 for sample 3 mean.
- When comparing our results from Table 5 to Table 3, we can notice that margin of error and width of confidence interval for t-distribution is definitely is greater than when we compare to Z-test.
- And, the reason for this difference is because according to central limit theorm, the distribution of a sample variable approximates a normal distribution (i.e., a “bell curve”) as the sample size becomes larger.

</FONT>


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.6. Sample 3 : Confidence Interval for Sample Proportion
</FONT>
</BR></B>

In this section, first we are going to going the calculate the proportion of sucess and failure of Sample 3 for values lower than 1.7
And, then we are to going to calculate confidence interval for the sample proportion with with 90%, 96% and 99% Confidence.

```{r message=FALSE, warning=FALSE}


# Calculation for sample proportion

nS3 <- 1500

Lower1.7S3 <- sum(S3 < 1.7)
Upper1.7S3 <- nS3 - Lower1.7S3

p_successS3 <- Lower1.7S3 / nS3
p_failureS3 <- Upper1.7S3 / nS3


# Vector Creation for Sample3
vectorS3 <- c(p_successS3, p_failureS3)


# Calculation for sample proportion

nPop <- 6556

Lower1.7Pop <- sum(SData$Population < 1.7)
Upper1.7Pop <- nPop - Lower1.7Pop



p_successPop <- Lower1.7Pop / nPop
p_failurePop <- Upper1.7Pop / nPop


# Vector Creation for Sample3
vectorPop <- c(p_successPop, p_failurePop)



# Matrix Creation for compiling all the Confidence Interval Vectors
#########################
Prop_Table <- matrix(c(vectorS3, vectorPop), nrow = 2, byrow = TRUE)


## Rounding Digits in Matrix
Prop_Table_Rounded <- round(Prop_Table, digits = 2)


## Naming Columns and Row Names in Table
colnames(Prop_Table_Rounded) <- c("Success", "Failure")

rownames(Prop_Table_Rounded) <- c("Sample 3", "Population")

# Table Creation of of Matrix Using Knitr Package
Prop_Table_Rounded %>%
  knitr::kable(
    caption = "Table 6: Proportion of Success and Failure for Sample 3 and Population",
    format = "html"
  ) %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )

# Creating Objects
nS3 <- 1500

# To find the find the count of obseervation lower than 1.7
Lower1.7S3 <- sum(S3 < 1.7)
Upper1.7S3 <- nS3 - Lower1.7S3

# Calculating the proportion for success and failure
p_successS3 <- Lower1.7S3 / nS3
p_failureS3 <- Upper1.7S3 / nS3


# Calculating Confidence for 90 %
####################################################
CL90S3 <- 0.90

# Calculation of Z Value for 90% CI
zvalue90S3 <- qnorm((1 + CL90S3) / 2)

# Calculation of Error for 90% CI
error90S3 <- zvalue90S3 * sqrt(((p_successS3 * p_failureS3) / nS3))

# Calculation of Upper and Lower Limit for 90% CI
CLL90S3 <- p_successS3 - error90S3
CLU90S3 <- p_successS3 + error90S3

# Calculation of C.I. Width for 90%
wd90S3 <- CLU90S3 - CLL90S3

# Vector Creation for 90% C.I.
vectorCI90S3 <- c(zvalue90S3, error90S3, CLU90S3, CLL90S3, wd90S3)


# Calculating Confidence for 96 %
####################################################
CL96S3 <- 0.96

# Calculation of Z Value for 96% CI
zvalue96S3 <- qnorm((1 + CL96S3) / 2)

# Calculation of Error for 96% CI
error96S3 <- zvalue96S3 * sqrt(((p_successS3 * p_failureS3) / nS3))

# Calculation of Upper and Lower Limit for 96% CI
CLL96S3 <- p_successS3 - error96S3
CLU96S3 <- p_successS3 + error96S3

# Calculation of C.I. Width for 96%
wd96S3 <- CLU96S3 - CLL96S3

# Vector Creation for 96% C.I.
vectorCI96S3 <- c(zvalue96S3, error96S3, CLU96S3, CLL96S3, wd96S3)


# Calculating Confidence for 99 %
####################################################
CL99S3 <- 0.99

# Calculation of Z Value for 99% CI
zvalue99S3 <- qnorm((1 + CL99S3) / 2)

# Calculation of Error for 99% CI
error99S3 <- zvalue99S3 * sqrt(((p_successS3 * p_failureS3) / nS3))

# Calculation of Upper and Lower Limit for 99% CI
CLL99S3 <- p_successS3 - error99S3
CLU99S3 <- p_successS3 + error99S3

# Calculation of C.I. Width for 99%
wd99S3 <- CLU99S3 - CLL99S3

# Vector Creation for 99% C.I.
vectorCI99S3 <- c(zvalue99S3, error99S3, CLU99S3, CLL99S3, wd99S3)


# Matrix Creation for compiling all the Confidence Interval Vectors
#########################
S3_Table <- matrix(c(vectorCI90S3, vectorCI96S3, vectorCI99S3),
  nrow = 3,
  byrow = TRUE
)


## Rounding Digits in Matrix
S3_Table_Rounded <- round(S3_Table, digits = 2)


## Naming Columns and Row Names in Table
colnames(S3_Table_Rounded) <- c("Z Value", "Mar of Error", "Upper C.L.", "Lower C.L.", "Width of C.I.")

rownames(S3_Table_Rounded) <- c("CI 90%", "CI 96%", "CI 99%")

# Table Creation of of Matrix Using Knitr Package
S3_Table_Rounded %>%
  knitr::kable(
    caption = "Table 7: Results of Sample 3 With Different Confidence Interval",
    format = "html"
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )
```


<BR>
<FONT SIZE = 4.5>

***Observations***
<P>

- From Table 6, we can see that probability of success for values lower than 1.7 are almost similar.
- From calculated values presented in Table 7, we can see popluation propprtio of 0.90 lies with population proportion value within the calculated 90% , 96%, and 99% confidence intervals for Probability of Success.
- We can notice that the z- value for Confidence Interval for 96% and 99% are different but rest of values like margin of error, upper and lower confidence are almost looking similar, because I have rounded the decimals to only 2 digits.
- But, I checked out that after rounding to 3, I found out that all the values are different indeed. 

</FONT>


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.7. Sample 4 : Confidence Interval for Sample Variance
</FONT>
</BR></B>


In this section, first we are going to going the calculate the variance for sample 4 and popluation and present the results and then , we will move on to calculate confidence interval for the sample variance of Sample 4 with with 90%, 96% and 99% Confidence.
Here, we are going to present all our results using inline R code at end.


```{r message=FALSE, warning=FALSE}


# Sample 4 : Basic Descriptive Statistics
nS4 <- 150
VarS4 <- var(S4)
StdS4 <- sd(S4)

# Calculating the Variance for Population
VarPop <- var(SData$Population)

# Inline R Code to Print Population and Sample Variance
paste("The variance of Sample 4 is", round(VarS4, 2))
paste("The variance of Population is", round(VarPop, 2))

# Creating Object for 90% Confidence Interval for Sample 4 Variance
########################################
CL90S4 <- 0.90
dfS4 <- nS4 - 1

# Calculating Alpha Value
alp90S4 <- (1 - CL90S4)

# Calculating Z value for Variance

Z90LS4 <- qchisq(p = alp90S4, df = dfS4, lower.tail = TRUE)

Z90RS4 <- qchisq(p = alp90S4, df = dfS4, lower.tail = FALSE)



# Creating Objects for Confidence Interval: Upper and Lower Limit

CLL90S4 <- ((dfS4) * (StdS4^2)) / Z90RS4

CLU90S4 <- ((dfS4) * (StdS4^2)) / Z90LS4

# Calculation of C.I. Width for 90
wd90S4 <- CLU90S4 - CLL90S4

# Creating Object for 96% Confidence Interval for Sample 4 Variance
########################################
CL96S4 <- 0.96
dfS4 <- nS4 - 1

# Calculating Alpha Value
alp96S4 <- (1 - CL96S4)

# Calculating Z value for Variance

Z96LS4 <- qchisq(p = alp96S4, df = dfS4, lower.tail = TRUE)

Z96RS4 <- qchisq(p = alp96S4, df = dfS4, lower.tail = FALSE)



# Creating Objects for Confidence Interval: Upper and Lower Limit

CLL96S4 <- ((dfS4) * (StdS4^2)) / Z96RS4

CLU96S4 <- ((dfS4) * (StdS4^2)) / Z96LS4

# Calculation of C.I. Width for 96
wd96S4 <- CLU96S4 - CLL96S4

# Creating Object for 99% Confidence Interval for Sample 4 Variance
########################################
CL99S4 <- 0.99
dfS4 <- nS4 - 1

# Calculating Alpha Value
alp99S4 <- (1 - CL99S4)

# Calculating Z value for Variance

Z99LS4 <- qchisq(p = alp99S4, df = dfS4, lower.tail = TRUE)

Z99RS4 <- qchisq(p = alp99S4, df = dfS4, lower.tail = FALSE)



# Creating Objects for Confidence Interval: Upper and Lower Limit

CLL99S4 <- ((dfS4) * (StdS4^2)) / Z99RS4

CLU99S4 <- ((dfS4) * (StdS4^2)) / Z99LS4

# Calculation of C.I. Width for 99
wd99S4 <- CLU99S4 - CLL99S4


# Inline R Code to present all the value calculated for 90% CI
paste("1.1. The X^2 left Value of Sample 4 with 90% Confidence Interval is", round(Z90LS4, 2))

paste("1.2. The X^2 right Value of Sample 4 With 90% Confidence Interval is", round(Z90RS4, 2))

paste("1.3. The Confidence Upper Limit for Sample 4 with 90% Confidence Interval is", round(CLU90S4, 2))

paste("1.4. The Confidence Lower Limit for Sample 4 with 90% Confidence Interval is", round(CLL90S4, 2))

paste("1.5. The Confidence Interval Width for Sample 4 with 90% Confidence Interval is", round(wd90S4, 2))


# Inline R Code to present all the value calculated for 96% CI
paste("2.1. The X^2 left Value of Sample 4 with 96% Confidence Interval is", round(Z96LS4, 2))

paste("2.2. The X^2 right Value of Sample 4 With 96% Confidence Interval is", round(Z96RS4, 2))

paste("2.3. The Confidence Upper Limit for Sample 4 with 96% Confidence Interval is", round(CLU96S4, 2))

paste("2.4. The Confidence Lower Limit for Sample 4 with 96% Confidence Interval is", round(CLL96S4, 2))

paste("2.5. The Confidence Interval Width for Sample 4 with 96% Confidence Interval is", round(wd96S4, 2))


# Inline R Code to present all the value calculated for 99% CI
paste("3.1. The X^2 left Value of Sample 4 with 99% Confidence Interval is", round(Z99LS4, 2))

paste("3.2. The X^2 right Value of Sample 4 With 99% Confidence Interval is", round(Z99RS4, 2))

paste("3.3. The Confidence Upper Limit for Sample 4 with 99% Confidence Interval is", round(CLU99S4, 2))

paste("3.4. The Confidence Lower Limit for Sample 4 with 99% Confidence Interval is", round(CLL99S4, 2))

paste("3.5. The Confidence Interval Width for Sample 4 with 99% Confidence Interval is", round(wd99S4, 2))
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>
- I have leant to find out x^2 right and x^2 left value by using a new R functions, called "qchisq()".
- The variance of population is 0.87, so we clearly notice the population variance is outside the 90% Confidence Interval with upper limit as 0.78 and lower limit as 0.58.
- Also, It is also outside the 96% Confidence Interval with upper limit as 0.83 and lower limit as 0.55.
- Only for 99% Confidence interval of sample variance, the population variance is within it's interval width.
- One thing particular, I have learned that for calculating the lower confidence limit, it's uses x^2 right value and vice versa which is bit atypical.


</FONT>


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.8. Sample 5 : Hypothesis Testing Using Using z-Test
</FONT>
</BR></B>

In this section, we are to perform hypothesis testing on sample 5, test our hypothesis that the population mean is indeed different from 1.05. 

Here is our hypothesis

                H0: µ=1.05   
                H1: µ ≠ 1.05

As, you can see that our alternative hypothesis asks for two tailed test, so first we are to find out the Z-test value, and then based on it's results we are going to find if we need to calculate right or left critical value.
And, then at last, based on results, we are going to see if we got enough evidence to reject the null hypothesis.


```{r message=FALSE, warning=FALSE}

# Creating Objects for Sample 5
nS5 <- 200
MeanS5 <- mean(S5)

# Creating Objects for Population
MeanPop <- mean(SData$Population)
StdPop <- sd(SData$Population)

CL95S5 <- 0.95

# Calculating Alpha Value
alp95S5 <- (1 - CL95S5)

# Z-Test
ZtestS5 <- (MeanS5 - MeanPop) / (StdPop / sqrt(nS5))

paste("The Z-test value for with 95 % Confidence Interval is", round(ZtestS5, digits = 2))


# Calculating Right Critical value as Z-test is positive

Z95RS5 <- qnorm((alp95S5 / 2) + CL95S5)

vectorS5 <- c(CL95S5, Z95RS5, ZtestS5)

paste("Is my Z Test Value Greater than Right Critical value?", " The answer is", ZtestS5 > Z95RS5)



## Preparing Matrix to present the table
HypothesisMatrix <- matrix(
  data = c(vectorS5),
  nrow = 1,
  byrow = TRUE
)

## Rounding Digits in Matrix
HypothesisMatrix_Rounded <- round(HypothesisMatrix, digits = 2)

colnames(HypothesisMatrix_Rounded) <- c("Confidence Interval", "Right Critical Value", "Z-test Value")

# Present the table using kableExta Package
knitr::kable(HypothesisMatrix_Rounded,
  caption = "Table 8: Sample 5: Result of Hypothesis Testing (Z-Test) ",
  format = "html",
  table.attr = "style=width: 40%", align = "lccrr",
  font_size = 8
) %>%
  kable_styling(bootstrap_options = c(
    "striped", "hover",
    "condensed", "responsive"
  )) %>%
  kable_classic(
    full_width = F,
    html_font = "Times New Roman"
  )
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>

- As, we can observe from table 8 that the Z-test value (3.19) is definitely greater than our right critical value (1.96) as we have obtained a positive Z-test value, so it means we have to perform right-tailed to check this.
- As our Z-test value is in critical region, so we can say that we have sufficent evidence to reject the null hypothesis.
- But then, we have to also remember that, there is still 5% chance that, we are making mistake because we have choosen 95% confidence Interval.
- Also, Type 1 error can also occur, where we rejected null hypothesis which was in this case, but it was true and should have been accepted. So, we have to find out the p-value , because it will give us the probability of Type 1 error.


</FONT>


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.9. Sample 5 : Hypothesis Testing Using P-Value Method
</FONT>
</BR></B>

Now, In this section instead of traditional method for hypothesis testing on Sample 4, we are goin to use p-value to find out we got enough evidence to reject the null hypothesis as mentioned in Section 2.8.


```{r message=FALSE, warning=FALSE}

# Calculating P Value from Z-test
pvalueS5 <- round(1 - pnorm(ZtestS5), digits = 3)


# Checking if the p-value is less than alpha value on right-tail
paste("Is my p-value smaller than alpha value?", " The answer is", pvalueS5 < alp95S5)

# Presenting the P- Value

paste("The p-value  is", pvalueS5)
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>

- After comparing the results from Task 2.8 and Task 2.9 , both answer came out to TRUE, means it we got enough evidence to reject the null hypothesis.
- Our p-value(0.001) also shows that the difference is also very significant between the null and alternative hypothesis, so there is less chance to get Type 1 (Sil, 2019).

</FONT>


<P>
<BR> <B>
<FONT SIZE = 4.75, COLOR ="#f94c56">
2.10. Sample 6 : Hypothesis Testing Using t-Test
</FONT>
</BR></B>

In last section, we are going to perform a hypothesis testing on Sample 6 using t-test, to test the hypothesis that the population mean is higher than 1.05, using α = 0.01.

Here is stated hypothesis

                  H0: µ = 1.05

                  H1: µ > 1.05



```{r message=FALSE, warning=FALSE}

# Creating Objects for Sample 5
nS6 <- 29
MeanS6 <- mean(S6)
alphaS6 <- 0.01
sdS6 <- sd(S6)

# Creating Objects for Population
MeanPop <- mean(SData$Population)
StdPop <- sd(SData$Population)


# calculating Degree of freedom
dfS6 <- nS6 - 1

# Calculating t-value
tvalueS6 <- qt(1 - alphaS6, dfS6)

# Performing the right tailed test based on hypothesis
ttestS6 <- (MeanS6 - MeanPop) / (sdS6 / sqrt(nS6))

# Checking if Z Test Value Greater than Right Critical value as it's right-tailed test.
paste("Is my Z Test Value Greater than Right Critical value?", " The answer is", ttestS6 > tvalueS6)

# Calculating P Value from t-test
pvalueS6 <- round(1 - pt(ttestS6, dfS6), digits = 3)



# Checking if the p-value is less than alpha value on right-tail
paste("Is my p-value smaller than alpha value?", " The answer is", pvalueS6 < alphaS6)

vectorS6 <- c(alphaS6, tvalueS6, ttestS6, pvalueS6)


# Making a matrix to present in table
HypothesisMatrix6 <- matrix(data = c(vectorS6), nrow = 1, byrow = TRUE)

## Rounding Digits in Matrix
HypothesisMatrix6_Rounded <- round(HypothesisMatrix6, digits = 2)

colnames(HypothesisMatrix6_Rounded) <- c("Alpha Value", "T-Value", "Test Value", "P-Value")

# Present the table using kableExta Package
knitr::kable(HypothesisMatrix6_Rounded,
  caption = "Table 9: Sample 6: Result of Hypothesis Testing (t-Test) ",
  format = "html",
  table.attr = "style=width: 40%", align = "lccrr"
) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

<BR>
<FONT SIZE = 4.5>

***Observations***
<P>
- Results on Table 9 shows that T-test value (0.42) is not greater than right critical value (2.47), but rather it is smaller,  and p-value(0.34) is also greater than alpha, 
- So, We can conclude that as of now we don't have enough evidence to reject the null hypothesis, thus status quo is maintained.

</FONT>

<P>
<BR> <B>
  <FONT SIZE = 5, COLOR ="#f70d1a">
  3. CONCLUSIONS 
  </FONT>
</BR></B>

- I have how both confidence intervals and hypothesis testing seek to infer a population parameter from a sample of data gathered from that population. Confidence intervals provide us with a range of potential values as well as an estimate of the precision for our parameter value.
- Hypothesis tests indicate our level of confidence in making conclusions about population parameters from our sample.
- Both confidence intervals and hypothesis intervals can be used in conjunction to support claims.
- According to the San Jose State University Statistics Department, hypothesis testing is one of the most important concepts in statistics because it determines whether something actually happened, whether certain treatments have positive effects, whether groups differ from one another, or whether one variable predicts another. In brief, I have learned how to demonstrate that your evidence is statistically significant and unlikely to have happened by chance alone.
- Also, I have learned how the confidence Interval of proportion and varinace are calculated and their dependency, especially with calculation of confidence interval for sample variance in Section 2.7.
- Also, gained knowledge about how p-value gives us more accurate picture to test our hypothesis.


<P>
<BR> <B>
  <FONT SIZE = 5, COLOR ="#f70d1a">
  4. REFERENCES 
  </FONT>
</BR></B>


- Poole, C. (1987). Beyond the confidence interval. American Journal of Public Health, 77(2), 195-199.
- Hazra, A. (2017). Using the confidence interval confidently. Journal of thoracic disease, 9(10), 4125.
- Sil, A., Betkerur, J., & Das, N. K. (2019). P-value demystified. Indian dermatology online journal, 10(6), 745.
- Bluman, A. (2014). Elementary Statistics: A step by step approach 9e. McGraw Hill.


<P>
<BR> <B>
  <FONT SIZE = 5, COLOR ="#f70d1a">
  5. APPENDIX 
  </FONT>
</BR></B>

An R Markdown file has been attached to this report. The name of the
file is Maheswar_M3Project.Rmd